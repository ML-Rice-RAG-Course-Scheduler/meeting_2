{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install chromadb sentence_transformers beautifulsoup4 requests"
      ],
      "metadata": {
        "id": "w-0ptKkI_4JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyhuejHa_zzv"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup # we use BeatifulSoup for webscraping\n",
        "term = \"202610\" #2025-2026 course catalog\n",
        "base_url = \"https://courses.rice.edu\"\n",
        "url_catalog = base_url + \"/admweb/!SWKSCAT.cat?p_action=CATALIST&p_term=\" + term # scrape data from courses.rice.edu\n",
        "\n",
        "# Get the HTML code of the page\n",
        "resp = requests.get(url_schedule)\n",
        "html_source = resp.text\n",
        "\n",
        "soup = BeautifulSoup(html_source, \"html.parser\") # our scraper\n",
        "\n",
        "courses = []\n",
        "\n",
        "for row in soup.select(\"tr\"): # iterate through each table row\n",
        "    cells = row.find_all(\"td\") # get all table data  cells in current table row\n",
        "    if len(cells) > 4 and cells[0].find(\"a\"): # skip rows that don't have enough cells (header or blank rows)\n",
        "        courses.append({\n",
        "            \"course\": cells[0].text.strip(),\n",
        "            \"title\": cells[1].text.strip(),\n",
        "            \"distribution_group\": cells[2].text.strip(),\n",
        "            \"diversity_credit\": cells[3].text.strip() != \"\",\n",
        "            \"credit_hours\": cells[4].text.strip(),\n",
        "        })\n",
        "\n",
        "        # Get the url\n",
        "        link_tag = cells[0].find(\"a\")\n",
        "        relative_url = link_tag['href']\n",
        "        full_url = base_url+relative_url\n",
        "\n",
        "        #Here, scrape the data from sub-page.\n",
        "\n",
        "        # Recommend using \"for row in soup.select(\"tr\")[:10]\" for the loop, since\n",
        "        # scraping sub-pages of a long list of courses may be a slow process, and unless\n",
        "        # you are sure your code correctly scrapes sub-pages, run it only on a small sublist of courses\n",
        "\n",
        "for course in courses:\n",
        "    print(course)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Get the model we will be using for embedding\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Initialize fields of our database\n",
        "documents = []\n",
        "metadatas = []\n",
        "ids = []\n",
        "id = 0\n",
        "\n",
        "# Iterate over our scraped courses\n",
        "for course in schedule_data:\n",
        "\n",
        "  # Create a single string that encapsulates course title, code, and description - maximum context for embedding\n",
        "  doc_text = f\"Course: {course['title']} : {course['course']}. Description: {course['description']}\"\n",
        "\n",
        "  documents.append(doc_text)\n",
        "  metadatas.append(course)\n",
        "  ids.append(str(id))\n",
        "  id += 1\n",
        "\n",
        "embeddings = model.encode(documents, show_progress_bar=True)"
      ],
      "metadata": {
        "id": "ELOLkOMh_4qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "\n",
        "\n",
        "'''\n",
        "You can use chromadb's embedding with following changes in code:\n",
        "\n",
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "embedding = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "db_path = 'rice_courses_db_chromadb_embedding'\n",
        "client = chromadb.PersistentClient(path = db_path)\n",
        "\n",
        "collection = client.create_collection(\n",
        "    name = \"rice_courses_chromadb_embedding\",\n",
        "    embedding_function=embedding\n",
        "    )\n",
        "collection.add(\n",
        "    documents = documents,\n",
        "    metadatas = metadatas,\n",
        "    ids = ids\n",
        "    )\n",
        "'''\n",
        "# Create out database\n",
        "\n",
        "db_path = 'rice_courses_db'\n",
        "client = chromadb.PersistentClient(path = db_path)\n",
        "collection = client.get_or_create_collection(\n",
        "    name = \"rice_courses\",\n",
        "    )\n",
        "\n",
        "# Add data to the database\n",
        "collection.add(\n",
        "    documents = documents,\n",
        "    metadatas = metadatas,\n",
        "    ids = ids\n",
        "    )"
      ],
      "metadata": {
        "id": "sCnZPPTAFT6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = collection.query(\n",
        "    query_texts = [\"Class about African history\"],\n",
        "    n_results = 1 # by default returns 10 closest results\n",
        ")\n",
        "print(results[\"documents\"])\n",
        "print(results['distances'])"
      ],
      "metadata": {
        "id": "g4jtCEC0A0_B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}